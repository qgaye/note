# Java中的锁

## Lock和synchronzied

Lock是个接口，使用时要用不同的实现(比如最常用的ReentrantLock)，而synchronzied是关键字

首先两者的不是一者代替另一者的关系，在大多数情况下推荐使用synchronzied，因为其会自动释放锁，但是也存在一些需要Lock的场景

synchronzied的问题：
- 效率低：获取锁时不能设定超时，不能中断正在获取锁的线程
- 不够灵活：加锁，释放锁时机单一，且一次只能加上一个锁
- 无法知道是否成功获取到锁

Lock的问题：
- Lock不会在异常或代码执行完成后自动释放锁(而synchronzied会自动释放锁)

Lock中的方法：
- lock：最普通的获取锁的方法，如果该锁已被其他线程持有，就进行等待(lock方法不能被中断，一旦发生死锁，就会一直等待)
- tryLock：尝试获取锁，如果当前锁没有被其他线程持有，获取成功返回true，反之返回false，该方法立即返回，即使拿不到锁也不会等待
- tryLock(long time, TimeUnit time)：与tryLock作用相同都是尝试获取锁，但是传入了超时时间，如果获取不到，会在超时时间内一直尝试获取
- lockInterruptibly：相当于超时时间为无限的tryLock
- unlock：解锁

tryLock(long time, TimeUnit time)和lockInterruptibly在等待锁的过程中都是可以被中断的

Lock最佳实践：
在lock之后紧跟try finally代码块，在try中进行逻辑处理，在finally中unlock，以保证无论是，情况都能被解锁(为什么不把lock操作也放在try的代码块中，这是因为只有在成功lock后才能unlock，否则会抛出IllegalMonitorStateException)

```java
lock.lock();
try {
    // do someting
} finally {
    lock.unlock();
}
```

可见性：
在Happens-Before原则中，Lock和synchronzied都保证在加锁前一定能够看到同一把锁解锁前的所有操作

## 乐观锁和悲观锁

乐观锁：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现
悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁

对于悲观锁来说：存在唤醒和阻塞的性能消耗，如果所有锁的线程永久阻塞，那么请求锁的线程也会永久阻塞的问题

在Java中：
乐观锁：atomic包下的原子类，是使用CAS实现的乐观锁
悲观锁：synchronzied，ReentrantLock等独占锁

使用场景：
乐观锁：读多写少
悲观锁：读少写多

因为虽然前期乐观锁消费资源比较少，但是如果其不断尝试写入，就会导致消耗的资源越来越多，而悲观锁的加锁是一劳永逸的，一旦锁住别的想要获取锁的就会被阻塞，因此悲观锁适合长时间修改资源的情况

## 可重入锁和不可重入锁

可重入锁：线程获取到了该锁后能够再次获取到该锁(比如synchronzied或ReentrantLock)
不可重入锁：线程获取到了该锁后不能再次获取到该锁

可重入锁的好处：
避免死锁：比如同一个类中一个synchronzied方法调用另一个synchronzied方法，如果synchronzied不是可重入锁，那么在调用另一个synchronzied方法时就会因为无法获取到该锁而发生死锁

可重入举例：

1. ReentrantLock

```java
lock.lock();
lock.getHoldCount(); // 重入次数1
lock.lock();
lock.getHoldCount(); // 重入次数2
```

2. synchronzied

```java
public synchronized void method1() {
    method2(); // 成功调用method2，即可重入获取this锁
}

public synchronized void method2() {
    // do something
}
```

## 公平锁和非公平锁

为什么需要非公平锁？因为正常情况下唤醒一个线程是有时间开销的，在这段时间开销内如果有其他正在运行中的线程来尝试获取，那么非公平锁是允许给这个“插队”线程的。所以这个非公平不是完全不公平，只是合理运用了唤醒这段时间

非公平锁不公平的地方就在于允许在唤醒排队中的线程时，允许别的线程的插队操作，但如果没有线程插队，那么其执行顺序还是公平的

而公平锁和非公平锁的实现原理就在于公平锁在尝试获取锁时会先调用`hasQueuedPredecessors`方法查看是否已经有在等待的线程了，如果有那就排队，而非公平锁不调用`hasQueuedPredecessors`，因此不论是否有排队的线程，都去尝试获取，因此正在运行的线程相比于等待中的线程没有唤醒的时间，于是就出现了等待中的线程无法获取到该锁而被运行中的线程“插队”的非公平的现象

公平锁：能保证各个线程间平等，每个线程在等待一段时间后一定能有运行机会，但会影响整体运行速度和吞吐量
非公平锁：因为允许在唤醒期间让别的线程抢到锁，因此运行速度和吞吐量得大提升，但存在某个线程一直无法抢到锁的情况

## 共享锁和排他锁

共享锁：一个锁可以同时被多个线程获取
排他锁：一个锁在某一时刻只能被一个线程占有，其他线程必须等待其释放该锁后才可以获得

ReentrantLock是排他锁
CountDownLatch是共享锁
ReentrantReadWriteLock中的ReadLock是共享锁，WriteLock是排他锁

具体介绍ReentrantReadWriteLock锁：

通过readLock()获取ReadLock读锁，通过writeLock()获取WriteLock写锁

具体加锁规则：
- 读锁是共享锁，因此多个线程可以同时获取读锁
- 写锁是排他锁，因此某一时间只能有一个线程占有
- 读锁和写锁是不共存的，当一个线程占有了读锁其他线程就无法获取写锁，同理当一个线程占有了写锁其他线程就无法获取读锁

插队规则：
因为锁存在公平和非公平之分，ReentrantReadWriteLock默认是非公平锁，就会存在“插队”的情况
公平锁：按线程进入的先后顺序获取锁
非公平锁：当插队的是写锁，是允许的。当插队的是读锁，此时判断队列中排队的下一个如果是写锁，那么不允许插队，如果是读锁，就允许插队

就非公平锁插队规则进行解释：
- 当插队的是写锁，那么直接去插队，只要此时无论写锁还是读锁被占有，那么该写锁的就无法插队，只能排队，而如果此时没有锁被占用，说明就是处在唤醒下一个等待线程的过程中，因此此时就允许写锁来插队执行
- 当插队的是读锁，此时如果下一个排队的是写锁，如果允许插队，就会存在插队的读锁发现线程中只被占用了读锁，因此插队的读锁也能加进去，进行执行，但是如果不断有新的插队读锁，那么就会导致排队的写锁永远无法执行，而如果下一个排队的是读锁，那么让读锁插队进来没有影响

升降级策略：
- 读锁升级为写锁，是不可以的(如果两个读锁同时申请写锁，那么都要等待另一个释放读锁，这就造成了死锁，因此不允许读锁升级)
- 写锁降级为读锁，是可以的(降级为读锁，这样别的读锁也能进行操作，能提升并发性能)

综上所述：ReentrantReadWriteLock适用于读多写少的情况，使得读操作间可以并行，不再单一阻塞

## 自旋锁和阻塞锁

阻塞锁：在获取锁失败后线程就进入阻塞，直到被唤醒
自旋锁：在获取锁失败后通过while循环不断重复尝试获取锁，直到获取到锁为止

可以发现自旋锁中通过死循环来不断请求锁，因此往往适用于能够快速获取到锁的情况，如果该锁一直被其他线程占用，那么该线程的死循环就白白消耗CPU，而如果持有锁的线程能够快速释放锁，那么挂起请求锁的线程再将它唤醒反而得不偿失，因为线程恢复和挂起也是有时间消耗的，因此不如让请求锁的线程“稍等一下”，不必阻塞就能直接获取到锁

atomic包下的基本使用了自旋锁实现，基于CAS，每次更新失败后会重新获取当前最新值再进行计算后再做更新，直到更新成功为止

总结：自旋锁适用于并发度不是特别高，临界区比较小(线程拿到锁后很快就释放)，多核CPU的情况

## 可中断锁和不可中断锁

不可中断锁：在尝试获取锁的过程中不可被中断(比如synchronzied)
可中断锁：在尝试获取锁的过程中可以被中断(比如ReentrantLock中的tryLock(time), lockInterruptibly()是可以中断的)

## JVM对锁的优化

- 自旋锁和自适应：JVM会对一直拿不到锁的自旋锁改为阻塞，或者设定一个自旋的次数，超过该值就进入阻塞
- 锁消除：对于不必要的锁JVM会消除掉
- 锁粗化：同一个锁不断被加锁释放锁，JVM会扩大范围，从而减少加锁释放锁的次数

## 编写代码时锁优化

- 缩小同步代码块
- 尽量不要锁住方法
- 减少请求锁的次数
- 避免认为制造“热点”(用个变量来保存代替每次同步代码块计算)
- 锁中尽量不要再包含锁
- 选择适合的锁或并发工具
